{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = cv2.imread('test1.png')\n",
    "img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "template = cv2.imread('4_masked.jpg', 0)\n",
    "\n",
    "height, width = template.shape[::]\n",
    "\n",
    "res = cv2.matchTemplate(img_gray, template, cv2.TM_SQDIFF)\n",
    "plt.imshow(res, cmap='gray')\n",
    "\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "top_left = min_loc  #Change to max_loc for all except for TM_SQDIFF\n",
    "bottom_right = (top_left[0] + width, top_left[1] + height)\n",
    "cv2.rectangle(img_rgb, top_left, bottom_right, (255, 0, 0), 2) \n",
    "\n",
    "cv2.imshow(\"Matched image\", img_rgb)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"palm.png\"\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "# cv2.imshow('palm image',img)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()\n",
    "# cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsvim = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "lower = np.array([0, 48, 80], dtype = \"uint8\")\n",
    "upper = np.array([20, 255, 255], dtype = \"uint8\")\n",
    "skinRegionHSV = cv2.inRange(hsvim, lower, upper)\n",
    "blurred = cv2.blur(skinRegionHSV, (2,2))\n",
    "ret,thresh = cv2.threshold(blurred,0,255,cv2.THRESH_BINARY)\n",
    "# cv2.imshow(\"thresh\", thresh)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()\n",
    "# cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = max(contours, key=lambda x: cv2.contourArea(x))\n",
    "cv2.drawContours(img, [contours], -1, (255,255,0), 2)\n",
    "\n",
    "# plt.imshow(img.astype('uint8'))\n",
    "# plt.show()\n",
    "cv2.imshow(\"contours\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# a) Reading a stream of images from a webcamera, and displaying the video\n",
    "# ----------------\n",
    "# For more information on reading and writing video: http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html\n",
    "# open the video camera no. 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# if not successful, exit program\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open the video cam\")\n",
    "    sys.exit()\n",
    "\n",
    "# create a window called \"MyVideo0\"\n",
    "cv2.namedWindow(\"MyVideo0\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# read a new frame from video\n",
    "ret, frame0 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Cannot read a frame from video stream\")\n",
    "\n",
    "# show the frame in \"MyVideo\" window\n",
    "cv2.imshow(\"MyVideo0\", frame0)\n",
    "\n",
    "# create windows\n",
    "cv2.namedWindow(\"Skin\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "len_history = 7\n",
    "my_motion_history = []\n",
    "fMH1 = np.zeros(np.shape(frame0)[:-1], dtype=np.uint8)\n",
    "for i in range(len_history):\n",
    "    my_motion_history.append(fMH1)\n",
    "\n",
    "\n",
    "while(1):\n",
    "    # read a new frame from video\n",
    "    ret, frame = cap.read()\n",
    "    # if not successful, break loop\n",
    "    if not ret:\n",
    "        print(\"Cannot read a frame from video stream\")\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"MyVideo0\", frame)\n",
    "\n",
    "    # ----------------\n",
    "    # b) Skin color detection\n",
    "    # ----------------\n",
    "    frame_dst = my_skin_detect(frame)\n",
    "    cv2.imshow(\"Skin\", frame_dst)\n",
    "\n",
    "    # ----------------\n",
    "    # c) Background differencing and motion energy\n",
    "    # ----------------\n",
    "\n",
    "    # call my_frame_differencing function\n",
    "    frame_dst = my_frame_differencing(frame0, frame)\n",
    "    cv2.imshow(\"FrameDiff\", frame_dst)\n",
    "\n",
    "    my_motion_history.pop(0)\n",
    "    my_motion_history.append(frame_dst)\n",
    "\n",
    "    # ----------------\n",
    "    #  d) Visualizing motion history\n",
    "    # ----------------\n",
    "\n",
    "    # call my_motion_energy function\n",
    "    myMH = my_motion_energy(my_motion_history)\n",
    "    cv2.imshow(\"MotionEnergy\", myMH) # show the frame in \"MyVideo\" window\n",
    "    frame0 = frame\n",
    "\n",
    "    # wait for 'esc' key press for 30ms. If 'esc' key is pressed, break loop\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        print(\"esc key is pressed by user\")\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
